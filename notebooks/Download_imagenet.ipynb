{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(image, MAX_SIZE):\n",
    "\n",
    "    H, W = image.shape[0:2]\n",
    "    \n",
    "    # Take the greater value, and use it for the ratio\n",
    "    max_ = np.min([H, W])\n",
    "    ratio = max_ / MAX_SIZE\n",
    "\n",
    "    W_ = W / ratio\n",
    "    H_ = H / ratio\n",
    "\n",
    "    W_, H_ = W_.astype(np.int32), H_.astype(np.int32)\n",
    "    image = cv2.resize(image, (W_,H_), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    H, W = image.shape[0:2]\n",
    "    \n",
    "    if H > MAX_SIZE:\n",
    "        margin = H - MAX_SIZE\n",
    "        start_y = margin // 2\n",
    "        image = image[start_y:start_y+MAX_SIZE, 0:W]\n",
    "    elif W > MAX_SIZE:\n",
    "        margin = W - MAX_SIZE\n",
    "        start_y = margin // 2\n",
    "        image =  image[:H, start_y: start_y+MAX_SIZE]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tfds(features):\n",
    "    image = features[\"image\"]\n",
    "    target = features[\"label\"]\n",
    "    return tf.cast(image, tf.float32), tf.squeeze(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tfds.load(name=\"imagenet2012\", split=tfds.Split.TRAIN)\n",
    "train_dataset = train_dataset.map(process_tfds)\n",
    "train_dataset = train_dataset.repeat(1)\n",
    "train_dataset = train_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dog_and_cat = np.arange(151, 294, dtype=np.int32)\n",
    "\n",
    "class_to_index = dict()\n",
    "for i, c in enumerate(classes_dog_and_cat):\n",
    "    class_to_index[c] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_index[286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "TRAIN_DATASET_DIR=\"./tfrecords/\"\n",
    "if not os.path.exists(TRAIN_DATASET_DIR):\n",
    "    os.mkdir(TRAIN_DATASET_DIR)\n",
    "    \n",
    "TRAIN_FILE = 'train.tfrecords'\n",
    "train_writer = tf.io.TFRecordWriter(os.path.join(TRAIN_DATASET_DIR,TRAIN_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "n_images = 0\n",
    "image_size = 64\n",
    "\n",
    "for image, label in train_dataset:\n",
    "    label = label.numpy()[0]\n",
    "    if label in classes_dog_and_cat:\n",
    "        image = resize_with_aspect_ratio(image.numpy()[0], image_size)\n",
    "    \n",
    "        image_h = image.shape[0]\n",
    "        image_w = image.shape[1]\n",
    "        img_raw = image.astype(np.float32).tostring()\n",
    "        target = class_to_index[label]\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                                    'height': _int64_feature(image_h),\n",
    "                                    'width': _int64_feature(image_w),\n",
    "                                    'image_raw': _bytes_feature(img_raw),\n",
    "                                    'target': _int64_feature(target)}))\n",
    "\n",
    "        train_writer.write(example.SerializeToString())\n",
    "        n_images+=1\n",
    "        \n",
    "print(\"Done!\")\n",
    "train_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180373"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_record_parser(record):\n",
    "    keys_to_features = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        'target': tf.io.FixedLenFeature((), tf.int64)\n",
    "    }\n",
    "\n",
    "    features = tf.io.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    image = tf.io.decode_raw(features['image_raw'], tf.float32)\n",
    "    label = tf.cast(features['target'], tf.int32)\n",
    "\n",
    "    # reshape input and annotation images\n",
    "    image = tf.reshape(image, (64, 64, 3), name=\"image_reshape\")\n",
    "\n",
    "    return image, tf.cast(label, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(\"./tfrecords/train.tfrecords\")\n",
    "train_dataset = train_dataset.map(tf_record_parser)\n",
    "train_dataset = train_dataset.repeat(1)\n",
    "train_dataset = train_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.47129 254.4475\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "for image, label in train_dataset:\n",
    "    if label.numpy()[0] == 133:\n",
    "        print(np.min(image), np.max(image))\n",
    "        plt.imshow(image[0]/255)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(classes, bins=143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0_cpu",
   "language": "python",
   "name": "tf2.0_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
